Big O: 
a fundamental concept in computer science and programming
that helps you analyze and describe the efficiency of algorithms.
Big O is a mathematical notation that describes the upper bound 
or worst case scenario for the time complexity of an alogorithm.
How does the runtime of an algorithm change as the imput data increases?
How does an algorithm scale with increased input size?

0(1) - Constant time
The runtime does not depend on the size of the input data. 
It remains constant, making it the most efficient scenario.
    Example: (Accessing an element in an array by its index.)

0(n) - Linear time
Algorithms with linear time complexity have a runtime that grows
linearly with the size of the input data. This means that if the
input data doubles in size, the runtime also doubles.
    Example: (Searching for a specific value in an unsorted list.)

O(n^2) - Quadratic Time
Algorithms with quadratic time complexity have runtimes that grow 
with the square of the input size. As the input data size increases, 
the runtime increases quadratically.
    Example: (Bubble Sort, a simple sorting algorithm.)

O(log n) - Logarithmic Time
Algorithms with logarithmic time complexity have runtimes that grow 
logarithmically with the size of the input data. Logarithmic time 
complexity is considered very efficient.
    Example: (Binary search in a sorted list.)


Overview:
Fastest:

O(1) - Constant Time: Lightning-fast! The algorithm's speed doesn't 
depend on how much data you have. It's like finding your favorite 
book on a perfectly organized bookshelf – it takes the same amount 
of time, whether you have 10 books or 1,000 books.

Pretty Fast:

O(log n) - Logarithmic Time: Still quite speedy! It grows slowly as 
you add more data. Think of it as finding a name in a phone book by 
repeatedly splitting it in half – it gets faster even if the phone 
book gets bigger.

Moderate:

O(n) - Linear Time: Respectable speed! If you have twice as much data, 
it takes about twice as long. It's like looking through a list of names 
one by one to find a match.

Slower:

O(n log n) - Linearithmic Time: It's faster than quadratic but slower 
than linear. Comparable to sorting a deck of cards quickly using smart
techniques.

Slower Still:

O(n^2) - Quadratic Time: Getting slower as you add data. Like checking 
every combination of items on a list against each other – not great for 
large lists.

Quite Slow:

O(2^n) - Exponential Time: Now we're talking about slow! It grows rapidly 
as you add data. Imagine a puzzle where you have to try every possible 
combination – it's really slow even for small puzzles.

Incredibly Slow:

O(n!) - Factorial Time: The slowest of all! It's like solving a complex 
puzzle where the number of possible arrangements explodes as you add more 
pieces. Practically unusable for large problems.











